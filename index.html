<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Multi-shot HD Stacking Camera</title>
<style>
  :root{font-family:system-ui,-apple-system,Segoe UI,Roboto,"Helvetica Neue",Arial;}
  body{background:#0f1724;color:#e6edf3;margin:0;padding:16px;display:flex;flex-direction:column;gap:12px;align-items:center;}
  .controls{display:flex;gap:8px;flex-wrap:wrap;align-items:center;}
  button{background:#0ea5a3;border:none;padding:8px 12px;border-radius:8px;color:#032;cursor:pointer;font-weight:600;}
  button:disabled{opacity:.45;cursor:not-allowed;}
  video, canvas{border-radius:12px;box-shadow:0 6px 18px rgba(2,6,23,.6);max-width:100%;width:360px;height:auto;background:#000;}
  .small{font-size:13px;opacity:.9}
  label{display:flex;gap:8px;align-items:center}
  input[type=range]{width:180px}
  .meta{font-size:12px;color:#9fb6c2}
  .row{display:flex;gap:10px;flex-wrap:wrap;align-items:center;}
  .danger{background:#ef4444;color:white}
</style>
</head>
<body>
  <h3>Multi-shot HD stacking (tries to use rear 48MP camera)</h3>

  <div class="row">
    <video id="preview" autoplay playsinline muted></video>
    <canvas id="result" width="360" height="270" style="display:block"></canvas>
  </div>

  <div class="controls">
    <button id="btnStart">Request Camera</button>
    <button id="btnCapture" disabled>Take Multi-Shot (8)</button>
    <button id="btnCombine" disabled>Combine / Stack</button>
    <button id="btnDownload" disabled>Download Result</button>
    <button id="btnStop" class="danger" disabled>Stop Camera</button>
  </div>

  <div class="row">
    <label class="small">Shots:
      <input id="shots" type="number" min="2" max="16" value="8" style="width:60px;margin-left:6px">
    </label>

    <label class="small">Delay(ms):
      <input id="delay" type="number" min="50" max="1000" value="150" style="width:80px;margin-left:6px">
    </label>

    <label class="small">Processing downscale factor:
      <input id="procFactor" type="number" min="1" max="8" value="4" style="width:60px;margin-left:6px">
    </label>

    <label class="small">Zoom:
      <input id="zoom" type="range" min="1" max="4" step="0.1" value="1">
    </label>
  </div>

  <div class="meta" id="status">Status: idle</div>

<script>
(async ()=>{

const preview = document.getElementById('preview');
const resultCanvas = document.getElementById('result');
const resultCtx = resultCanvas.getContext('2d');
const btnStart = document.getElementById('btnStart');
const btnCapture = document.getElementById('btnCapture');
const btnCombine = document.getElementById('btnCombine');
const btnDownload = document.getElementById('btnDownload');
const btnStop = document.getElementById('btnStop');
const shotsInput = document.getElementById('shots');
const delayInput = document.getElementById('delay');
const procFactorInput = document.getElementById('procFactor');
const zoomInput = document.getElementById('zoom');
const status = document.getElementById('status');

let stream = null;
let track = null;
let imageCapture = null;
let capturedBitmaps = []; // array of ImageBitmap
let lastCombineBitmap = null;

function setStatus(s){ status.textContent = 'Status: ' + s; }

async function startCamera(){
  setStatus('requesting camera — asking for rear, high-res');
  try{
    // Request environment (rear) camera and very large ideal resolution (browser/device chooses)
    stream = await navigator.mediaDevices.getUserMedia({
      audio: false,
      video: {
        facingMode: { ideal: "environment" },
        width: { ideal: 8000 },
        height: { ideal: 6000 }
      }
    });
    preview.srcObject = stream;
    track = stream.getVideoTracks()[0];
    // try ImageCapture for higher-quality photo capture if supported
    try{ imageCapture = new ImageCapture(track); }catch(e){ imageCapture = null; }
    btnCapture.disabled = false;
    btnStop.disabled = false;
    setStatus('camera started — actual settings will be shown soon');
    // show actual settings after metadata loads
    preview.onloadedmetadata = () => {
      const w = preview.videoWidth, h = preview.videoHeight;
      setStatus(`camera active — preview ${w}×${h}. If lower than expected, browser/camera limited it.`);
      // adapt result canvas to preview initial aspect
      resultCanvas.width = w/4;
      resultCanvas.height = h/4;
    };
  }catch(err){
    console.error(err);
    setStatus('camera permission denied or error: ' + (err.message || err));
    alert('Unable to access camera: ' + (err.message || err));
  }
}

async function stopCamera(){
  if(stream){
    stream.getTracks().forEach(t=>t.stop());
    stream = null; track = null; imageCapture = null;
    preview.srcObject = null;
    btnCapture.disabled = true;
    btnCombine.disabled = true;
    btnDownload.disabled = true;
    btnStop.disabled = true;
    setStatus('camera stopped');
  }
}

// capture a single frame as ImageBitmap (prefer ImageCapture.takePhoto if available)
async function captureFrameAsBitmap(){
  if(imageCapture && imageCapture.takePhoto){
    // Some browsers support takePhoto -> Blob
    try{
      const blob = await imageCapture.takePhoto(); // may reject in some devices
      return await createImageBitmap(blob);
    }catch(e){
      // fallback to canvas capture
    }
  }
  // fallback: draw current video frame to canvas then to bitmap
  const w = preview.videoWidth, h = preview.videoHeight;
  const c = new OffscreenCanvas(w, h);
  const ctx = c.getContext('2d');
  ctx.drawImage(preview, 0, 0, w, h);
  return await c.transferToImageBitmap();
}

// quick utility to convert ImageBitmap to ImageData (draw to canvas)
function imageBitmapToImageData(bitmap, targetW, targetH){
  const c = new OffscreenCanvas(targetW, targetH);
  const ctx = c.getContext('2d');
  ctx.drawImage(bitmap, 0, 0, targetW, targetH);
  return ctx.getImageData(0,0,targetW,targetH);
}

// grayscale conversion
function grayscaleFromImageData(imgData){
  const d = imgData.data; const w = imgData.width, h = imgData.height;
  const out = new Float32Array(w*h);
  for(let i=0, p=0;i<w*h;i++, p+=4){
    out[i] = (0.299*d[p] + 0.587*d[p+1] + 0.114*d[p+2]); // 0-255
  }
  return {data: out, w, h};
}

// find best translation offset between baseGrayscale and otherGrayscale
// searchRange in pixels. This uses a simple sum-of-squared-differences (SSD) with stride for speed.
function findBestOffset(base, other, searchRange=20, stride=2){
  const bw = base.w, bh = base.h;
  const ow = other.w, oh = other.h;
  // assume same dims
  const dataB = base.data, dataO = other.data;
  let best = {dx:0, dy:0, score:Infinity};
  // limit loops by stride
  for(let dy=-searchRange; dy<=searchRange; dy+=stride){
    for(let dx=-searchRange; dx<=searchRange; dx+=stride){
      let ssd = 0, count = 0;
      // compute overlap bounds
      const x0 = Math.max(0, dx), x1 = Math.min(bw, bw + dx);
      const y0 = Math.max(0, dy), y1 = Math.min(bh, bh + dy);
      // iterate within overlap
      for(let y=y0; y<y1; y+=2){ // inner stride to speed further
        const by = y, oy = y - dy;
        let bIndex = by * bw + x0;
        let oIndex = oy * ow + (x0 - dx);
        for(let x = x0; x < x1; x+=2){
          const db = dataB[bIndex], do2 = dataO[oIndex];
          const diff = db - do2;
          ssd += diff*diff;
          count++;
          bIndex += 2; oIndex += 2;
        }
      }
      if(count===0) continue;
      ssd = ssd / count;
      if(ssd < best.score){
        best = {dx, dy, score:ssd};
      }
    }
  }
  // refine around best with stride=1
  const refineRange = 2;
  let refined = best;
  for(let dy=best.dy - refineRange; dy<=best.dy + refineRange; dy++){
    for(let dx=best.dx - refineRange; dx<=best.dx + refineRange; dx++){
      let ssd = 0, count = 0;
      const x0 = Math.max(0, dx), x1 = Math.min(bw, bw + dx);
      const y0 = Math.max(0, dy), y1 = Math.min(bh, bh + dy);
      for(let y=y0; y<y1; y++){
        const by = y, oy = y - dy;
        let bIndex = by * bw + x0;
        let oIndex = oy * ow + (x0 - dx);
        for(let x = x0; x < x1; x++){
          const db = dataB[bIndex], do2 = dataO[oIndex];
          const diff = db - do2;
          ssd += diff*diff;
          count++;
          bIndex++; oIndex++;
        }
      }
      if(count===0) continue;
      ssd = ssd / count;
      if(ssd < refined.score){
        refined = {dx, dy, score:ssd};
      }
    }
  }
  return {dx: refined.dx, dy: refined.dy};
}

// combine images given offsets, produce ImageData (float accumulation -> then normalize)
async function combineBitmapsFullRes(bitmaps, offsets, combineScale=1){
  // combine at scaled resolution combineScale (1 = full)
  const base = bitmaps[0];
  const w = Math.round(base.width * combineScale);
  const h = Math.round(base.height * combineScale);
  const outArr = new Float32Array(w*h*4);
  const countArr = new Uint8Array(w*h);
  const tempCanvas = new OffscreenCanvas(w, h);
  const tctx = tempCanvas.getContext('2d');
  // for each image, draw scaled and read ImageData, then add with shift offsets (scaled)
  for(let i=0;i<bitmaps.length;i++){
    tctx.clearRect(0,0,w,h);
    tctx.drawImage(bitmaps[i], 0,0, w, h);
    const img = tctx.getImageData(0,0,w,h);
    const dx = Math.round(offsets[i].dx * combineScale);
    const dy = Math.round(offsets[i].dy * combineScale);
    // accumulate
    for(let y=0;y<h;y++){
      const sy = y - dy;
      if(sy < 0 || sy >= h) continue;
      for(let x=0;x<w;x++){
        const sx = x - dx;
        if(sx < 0 || sx >= w) continue;
        const srcIdx = (sy * w + sx) * 4;
        const dstIdx = (y * w + x) * 4;
        outArr[dstIdx]   += img.data[srcIdx];
        outArr[dstIdx+1] += img.data[srcIdx+1];
        outArr[dstIdx+2] += img.data[srcIdx+2];
        outArr[dstIdx+3] += img.data[srcIdx+3];
        countArr[y*w + x] += 1;
      }
    }
  }
  // normalize into Uint8ClampedArray
  const final = new Uint8ClampedArray(w*h*4);
  for(let i=0, p=0;i<w*h;i++, p+=4){
    const c = countArr[i] || 1;
    final[p]   = Math.min(255, Math.round(outArr[p] / c));
    final[p+1] = Math.min(255, Math.round(outArr[p+1] / c));
    final[p+2] = Math.min(255, Math.round(outArr[p+2] / c));
    final[p+3] = 255;
  }
  const outImageData = new ImageData(final, w, h);
  return outImageData;
}

// Event handlers
btnStart.addEventListener('click', async ()=>{
  btnStart.disabled = true;
  await startCamera();
});

btnStop.addEventListener('click', async ()=>{
  await stopCamera();
  btnStart.disabled = false;
});

btnCapture.addEventListener('click', async ()=>{
  const n = Math.max(2, Math.min(16, parseInt(shotsInput.value || 8)));
  const delay = Math.max(20, parseInt(delayInput.value || 150));
  capturedBitmaps = [];
  btnCapture.disabled = true;
  btnCombine.disabled = true;
  btnDownload.disabled = true;
  setStatus(`Capturing ${n} shots... Keep camera steady, slight handheld motion is okay.`);
  // warm-up
  await new Promise(r=>setTimeout(r,100));
  for(let i=0;i<n;i++){
    try{
      const bmp = await captureFrameAsBitmap();
      capturedBitmaps.push(bmp);
      setStatus(`Captured ${capturedBitmaps.length}/${n}`);
    }catch(e){
      console.error('capture error', e);
      setStatus('capture error: ' + e.message);
    }
    await new Promise(r=>setTimeout(r, delay));
  }
  setStatus(`Captured ${capturedBitmaps.length} images. Ready to combine.`);
  btnCombine.disabled = false;
  btnCapture.disabled = false;
});

btnCombine.addEventListener('click', async ()=>{
  if(capturedBitmaps.length < 2){ alert('Need at least 2 shots.'); return; }
  btnCombine.disabled = true;
  setStatus('Analyzing & aligning images (this may take a few seconds)...');
  try{
    const procFactor = Math.max(1, Math.min(8, parseInt(procFactorInput.value || 4)));
    // create downscaled grayscale versions for alignment
    const baseBitmap = capturedBitmaps[0];
    const procW = Math.max(200, Math.round(baseBitmap.width / procFactor));
    const procH = Math.max(200, Math.round(baseBitmap.height / procFactor));
    const baseImg = imageBitmapToImageData(baseBitmap, procW, procH);
    const baseGray = grayscaleFromImageData(baseImg);
    const offsets = [{dx:0, dy:0}];
    for(let i=1;i<capturedBitmaps.length;i++){
      const otherImg = imageBitmapToImageData(capturedBitmaps[i], procW, procH);
      const otherGray = grayscaleFromImageData(otherImg);
      // search range proportional to size
      const search = Math.round(Math.min(procW, procH) * 0.03) + 8; // ~3% of dimension with min
      const off = findBestOffset(baseGray, otherGray, search, 2);
      offsets.push(off);
      setStatus(`Aligned image ${i+1}/${capturedBitmaps.length}: dx=${off.dx}, dy=${off.dy}`);
      await new Promise(r=>setTimeout(r, 20)); // yield
    }
    setStatus('Combining at reasonable resolution (will try near-full).');
    // combineScale: try 0.5 if device might struggle; choose based on width
    let combineScale = 1;
    // if extremely large, reduce to 0.5 for safety
    if(baseBitmap.width > 4000) combineScale = 0.6;
    if(baseBitmap.width > 6000) combineScale = 0.4;
    const combineScaleText = combineScale===1? 'full' : (Math.round(combineScale*100)+'%');
    setStatus(`Combining using ${combineScaleText} of original resolution...`);
    const outImageData = await combineBitmapsFullRes(capturedBitmaps, offsets, combineScale);
    // draw to result canvas (fit to preview width)
    const displayW = preview.videoWidth || outImageData.width;
    const displayH = preview.videoHeight || outImageData.height;
    resultCanvas.width = Math.round(displayW / Math.max(1, procFactor/2));
    resultCanvas.height = Math.round(resultCanvas.width * outImageData.height / outImageData.width);
    // draw final (use an offscreen canvas first sized to final image)
    const off = new OffscreenCanvas(outImageData.width, outImageData.height);
    const octx = off.getContext('2d');
    octx.putImageData(outImageData, 0, 0);
    // store lastCombineBitmap for zoom/download
    lastCombineBitmap = await off.transferToImageBitmap();
    // draw scaled to visible result canvas
    resultCtx.clearRect(0,0,resultCanvas.width,resultCanvas.height);
    resultCtx.imageSmoothingEnabled = true;
    resultCtx.drawImage(lastCombineBitmap, 0,0, resultCanvas.width, resultCanvas.height);
    setStatus('Combine done. Use Zoom slider and Download.');
    btnDownload.disabled = false;
    btnCombine.disabled = false;
  }catch(e){
    console.error(e);
    setStatus('Error during combining: ' + (e.message || e));
    btnCombine.disabled = false;
  }
});

// Zoom handler: crop center and scale to result canvas
zoomInput.addEventListener('input', ()=>{
  if(!lastCombineBitmap) return;
  const z = parseFloat(zoomInput.value || 1);
  // crop a centered rectangle inversely proportional to zoom
  const bw = lastCombineBitmap.width, bh = lastCombineBitmap.height;
  const cropW = Math.round(bw / z);
  const cropH = Math.round(bh / z);
  const sx = Math.round((bw - cropW)/2);
  const sy = Math.round((bh - cropH)/2);
  const off = new OffscreenCanvas(cropW, cropH);
  const octx = off.getContext('2d');
  octx.drawImage(lastCombineBitmap, sx, sy, cropW, cropH, 0,0, cropW, cropH);
  // draw to visible result canvas (fit)
  resultCanvas.width = Math.min(1024, Math.round(resultCanvas.width || 360));
  resultCanvas.height = Math.round(resultCanvas.width * cropH / cropW);
  resultCtx.imageSmoothingEnabled = true;
  resultCtx.clearRect(0,0,resultCanvas.width,resultCanvas.height);
  resultCtx.drawImage(off.transferToImageBitmap ? off.transferToImageBitmap() : off, 0,0, resultCanvas.width, resultCanvas.height);
});

btnDownload.addEventListener('click', async ()=>{
  if(!lastCombineBitmap){ alert('No combined image yet'); return; }
  // create temporary canvas at full combined size and toBlob
  const c = document.createElement('canvas');
  c.width = lastCombineBitmap.width;
  c.height = lastCombineBitmap.height;
  const ctx = c.getContext('2d');
  ctx.drawImage(lastCombineBitmap, 0,0);
  c.toBlob(blob=>{
    const a = document.createElement('a');
    a.href = URL.createObjectURL(blob);
    a.download = 'stacked_hd.png';
    a.click();
    URL.revokeObjectURL(a.href);
  }, 'image/png');
});

// cleanup on unload
window.addEventListener('beforeunload', ()=>{ if(stream) stream.getTracks().forEach(t=>t.stop()); });

})(); // IIFE
</script>
</body>
</html>
